{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir5kuvGILTog",
        "outputId": "945b4cf2-51dd-435c-f877-6a60b2a9fc69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving figures to: figures_dataset\n",
            "metric embeddings: (145, 768)\n",
            "metric names: 145\n",
            "train: (5000, 5)\n",
            "test: (3638, 4)\n"
          ]
        }
      ],
      "source": [
        "# ======================================================\n",
        "# DATASET VISUALIZATION SCRIPT\n",
        "# ======================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Create folder\n",
        "FIG_DIR = \"figures_dataset\"\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "print(\"Saving figures to:\", FIG_DIR)\n",
        "\n",
        "# ======================================================\n",
        "# 1. Load files\n",
        "# ======================================================\n",
        "\n",
        "# metric embeddings\n",
        "metric_emb = np.load(\"metric_name_embeddings.npy\")\n",
        "\n",
        "# metric names (JSON list)\n",
        "with open(\"metric_names.json\", \"r\") as f:\n",
        "    metric_names = json.load(f)\n",
        "\n",
        "# train & test (JSON array, NOT jsonl)\n",
        "train_df = pd.read_json(\"train_data.json\")\n",
        "test_df = pd.read_json(\"test_data.json\")\n",
        "\n",
        "print(\"metric embeddings:\", metric_emb.shape)\n",
        "print(\"metric names:\", len(metric_names))\n",
        "print(\"train:\", train_df.shape)\n",
        "print(\"test:\", test_df.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 2. Visualize metric embeddings\n",
        "# ======================================================\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2)\n",
        "metric_pca = pca.fit_transform(metric_emb)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(metric_pca[:,0], metric_pca[:,1], s=60)\n",
        "for i, name in enumerate(metric_names):\n",
        "    plt.text(metric_pca[i,0]+0.01, metric_pca[i,1]+0.01, name, fontsize=7)\n",
        "plt.title(\"Metric Embeddings - PCA\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/metric_embeddings_pca.png\")\n",
        "plt.close()\n",
        "\n",
        "# TSNE (better perplexity)\n",
        "tsne = TSNE(n_components=2, perplexity=20, random_state=42)\n",
        "metric_tsne = tsne.fit_transform(metric_emb)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(metric_tsne[:,0], metric_tsne[:,1], s=60)\n",
        "for i, name in enumerate(metric_names):\n",
        "    plt.text(metric_tsne[i,0]+0.01, metric_tsne[i,1]+0.01, name, fontsize=7)\n",
        "plt.title(\"Metric Embeddings - tSNE\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/metric_embeddings_tsne.png\")\n",
        "plt.close()\n",
        "\n",
        "# Norm distribution\n",
        "norms = np.linalg.norm(metric_emb, axis=1)\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.bar(range(len(metric_names)), norms)\n",
        "plt.xticks(range(len(metric_names)), metric_names, rotation=90, fontsize=6)\n",
        "plt.title(\"Embedding Norms per Metric\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/metric_embedding_norms.png\")\n",
        "plt.close()\n",
        "\n",
        "# Cosine similarity heatmap\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cos_sim = cosine_similarity(metric_emb)\n",
        "\n",
        "plt.figure(figsize=(14,12))\n",
        "sns.heatmap(\n",
        "    cos_sim,\n",
        "    xticklabels=metric_names,\n",
        "    yticklabels=metric_names,\n",
        "    cmap=\"viridis\",\n",
        "    cbar=True\n",
        ")\n",
        "plt.xticks(rotation=90, fontsize=6)\n",
        "plt.yticks(fontsize=6)\n",
        "plt.title(\"Cosine Similarity between Metric Embeddings\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/metric_embeddings_cosine_heatmap.png\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "oE72_VbQL59O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8gJ4vnGN6mS",
        "outputId": "8a064e73-af9c-4d0c-f8c3-44c4a013545d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['metric_name', 'score', 'user_prompt', 'response', 'system_prompt'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 3. Training Data Visualization\n",
        "# ======================================================\n",
        "\n",
        "# 1. Score histogram\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.histplot(train_df[\"score\"], bins=40, kde=True, color=\"blue\", alpha=0.7)\n",
        "plt.xlabel(\"Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Train Score Distribution\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/train_score_hist.png\")\n",
        "plt.close()\n",
        "\n",
        "# 2. Score boxplot\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x=train_df[\"score\"], color=\"lightblue\")\n",
        "plt.title(\"Score Boxplot\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/train_score_box.png\")\n",
        "plt.close()\n",
        "\n",
        "# 3. Prompt text length\n",
        "train_df[\"user_len\"] = train_df[\"user_prompt\"].apply(lambda x: len(str(x)))\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.histplot(train_df[\"user_len\"], bins=40, kde=True)\n",
        "plt.title(\"User Prompt Text Length (Characters)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/train_user_prompt_length.png\")\n",
        "plt.close()\n",
        "\n",
        "# 4. Response text length\n",
        "train_df[\"response_len\"] = train_df[\"response\"].apply(lambda x: len(str(x)))\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.histplot(train_df[\"response_len\"], bins=40, kde=True, color=\"orange\")\n",
        "plt.title(\"Response Text Length (Characters)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/train_response_length.png\")\n",
        "plt.close()\n",
        "\n",
        "# 5. Metric name counts\n",
        "plt.figure(figsize=(10,5))\n",
        "train_df[\"metric_name\"].value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Metric Name Frequency in Training Data\")\n",
        "plt.xlabel(\"Metric Name\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/train_metric_name_distribution.png\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGvki3IXLz2q",
        "outputId": "5d4fd682-0d74-4034-b449-bb1f1fb75f2b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-193361145.py:47: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
            "  plt.tight_layout()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 4. Test Data Visualization\n",
        "# ======================================================\n",
        "\n",
        "# Prompt length\n",
        "test_df[\"user_len\"] = test_df[\"user_prompt\"].apply(lambda x: len(str(x)))\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.histplot(test_df[\"user_len\"], bins=40, kde=True, color=\"orange\")\n",
        "plt.title(\"Test User Prompt Length Distribution\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/test_user_prompt_length.png\")\n",
        "plt.close()\n",
        "\n",
        "# Response length\n",
        "test_df[\"response_len\"] = test_df[\"response\"].apply(lambda x: len(str(x)))\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.histplot(test_df[\"response_len\"], bins=40, kde=True, color=\"green\")\n",
        "plt.title(\"Test Response Length Distribution\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/test_response_length.png\")\n",
        "plt.close()\n",
        "\n",
        "# System prompt length (if not empty)\n",
        "test_df[\"system_len\"] = test_df[\"system_prompt\"].apply(lambda x: len(str(x)))\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.histplot(test_df[\"system_len\"], bins=40, kde=True, color=\"purple\")\n",
        "plt.title(\"Test System Prompt Length Distribution\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/test_system_prompt_length.png\")\n",
        "plt.close()\n",
        "\n",
        "# Metric name counts\n",
        "plt.figure(figsize=(10,5))\n",
        "test_df[\"metric_name\"].value_counts().plot(kind=\"bar\", color=\"orange\")\n",
        "plt.title(\"Metric Name Frequency in Test Data\")\n",
        "plt.xlabel(\"Metric Name\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/test_metric_name_distribution.png\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8YzhtCXLxAI",
        "outputId": "fbe1fcf7-96dd-4ee7-a6e8-27888d6ffc0e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-782892341.py:38: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
            "  plt.tight_layout()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 5. Compare Train vs Test\n",
        "# ======================================================\n",
        "\n",
        "# ---- 1. Compare user prompt length ----\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(train_df[\"user_len\"], bins=40, alpha=0.5, label=\"Train\", color=\"blue\")\n",
        "plt.hist(test_df[\"user_len\"], bins=40, alpha=0.5, label=\"Test\", color=\"orange\")\n",
        "plt.title(\"User Prompt Length: Train vs Test\")\n",
        "plt.xlabel(\"Length (characters)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/train_vs_test_user_prompt_length.png\")\n",
        "plt.close()\n",
        "\n",
        "# ---- 2. Compare response length ----\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(train_df[\"response_len\"], bins=40, alpha=0.5, label=\"Train\", color=\"blue\")\n",
        "plt.hist(test_df[\"response_len\"], bins=40, alpha=0.5, label=\"Test\", color=\"orange\")\n",
        "plt.title(\"Response Length: Train vs Test\")\n",
        "plt.xlabel(\"Length (characters)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/train_vs_test_response_length.png\")\n",
        "plt.close()\n",
        "\n",
        "# ---- 3. Compare metric_name distribution ----\n",
        "plt.figure(figsize=(10,5))\n",
        "train_df[\"metric_name\"].value_counts().sort_index().plot(kind=\"bar\", alpha=0.5, label=\"Train\", color=\"blue\")\n",
        "test_df[\"metric_name\"].value_counts().sort_index().plot(kind=\"bar\", alpha=0.5, label=\"Test\", color=\"orange\")\n",
        "plt.title(\"Metric Distribution: Train vs Test\")\n",
        "plt.xlabel(\"Metric Name\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/train_vs_test_metric_distribution.png\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMNPzJ-nOoy8",
        "outputId": "584b7bc3-30ed-470a-c9f9-d8d34ce62008"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2281765738.py:37: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
            "  plt.tight_layout()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# RESNET-MLP pipeline (full): MSE + KL(hist) + SWA + EMA + per-fold quantile mapping\n",
        "# ================================================================\n",
        "import os, time, math, random\n",
        "import numpy as np, pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from torch.optim.swa_utils import AveragedModel\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "NFOLDS = 5\n",
        "EPOCHS = 24\n",
        "BATCH = 256\n",
        "LR = 2.5e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "# histogram params\n",
        "NUM_BINS = 200\n",
        "SIGMA_BIN = 0.15\n",
        "LAMBDA_KL = 0.08   # try slightly larger than before\n",
        "\n",
        "SWA_START_FRAC = 0.7\n",
        "EMA_DECAY = 0.999\n",
        "\n",
        "# ResNet-MLP hyperparams\n",
        "INPUT_DIM = None   # filled after loading X\n",
        "HIDDEN_DIM = 1024   # base hidden dimension (can tune: 512, 768, 1024)\n",
        "NUM_BLOCKS = 8      # depth: 6-12 typical\n",
        "MLP_EXPAND = 4      # inner expansion factor inside block\n",
        "DROPOUT = 0.12\n",
        "\n",
        "# ---------------- Load features ----------------\n",
        "X = np.load(\"X_all.npy\").astype(np.float32)\n",
        "y = np.load(\"y_all.npy\").astype(np.float32)\n",
        "\n",
        "test_metric = np.load(\"test_metric_embs.npy\")\n",
        "test_text   = np.load(\"test_text_embs.npy\")\n",
        "\n",
        "dot = np.sum(test_metric * test_text, axis=1)\n",
        "norms = (np.linalg.norm(test_metric, axis=1) * np.linalg.norm(test_text, axis=1)) + 1e-9\n",
        "cos_test = (dot / norms).reshape(-1,1).astype(np.float32)\n",
        "absdiff_test = np.abs(test_metric - test_text).astype(np.float32)\n",
        "prod_test    = (test_metric * test_text).astype(np.float32)\n",
        "concat_test  = np.hstack([test_metric.astype(np.float32), test_text.astype(np.float32)])\n",
        "X_test = np.hstack([concat_test, absdiff_test, prod_test, cos_test]).astype(np.float32)\n",
        "\n",
        "print(\"X\", X.shape, \"y\", y.shape, \"X_test\", X_test.shape)\n",
        "INPUT_DIM = X.shape[1]\n",
        "\n",
        "# ---------------- target pdf ----------------\n",
        "def build_target_pdf(num_bins=NUM_BINS):\n",
        "    bins = np.linspace(0,10,num_bins+1)\n",
        "    centers = 0.5*(bins[:-1] + bins[1:])\n",
        "    pdf_low = np.exp(-0.5*((centers-0.9)/0.25)**2)\n",
        "    pdf_high = 1.0 * np.exp(-0.5*((centers-8.6)/0.6)**2)\n",
        "    pdf_mid = 0.08 * np.exp(-0.5*((centers-4.0)/1.3)**2)\n",
        "    pdf = pdf_low + pdf_high + pdf_mid\n",
        "    pdf = np.maximum(pdf, 1e-12)\n",
        "    pdf = pdf / pdf.sum()\n",
        "    return centers.astype(np.float32), pdf.astype(np.float32)\n",
        "\n",
        "BIN_CENTERS, TARGET_PDF = build_target_pdf(NUM_BINS)\n",
        "BIN_CENTERS_T = torch.tensor(BIN_CENTERS, dtype=torch.float32, device=DEVICE)\n",
        "TARGET_PDF_T  = torch.tensor(TARGET_PDF, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "# ---------------- soft histogram & KL ----------------\n",
        "def soft_histogram_torch(preds, bin_centers_t, sigma=SIGMA_BIN):\n",
        "    # preds: (B,), bin_centers_t: (M,)\n",
        "    d = preds.unsqueeze(1) - bin_centers_t.unsqueeze(0)   # (B, M)\n",
        "    w = torch.exp(-0.5 * (d / sigma)**2)                 # (B, M)\n",
        "    hist = w.sum(dim=0)                                   # (M,)\n",
        "    hist = hist / (hist.sum() + 1e-12)\n",
        "    return hist\n",
        "\n",
        "def kl_hist_loss_torch(preds, target_pdf_t=TARGET_PDF_T, bin_centers_t=BIN_CENTERS_T, sigma=SIGMA_BIN):\n",
        "    hist = soft_histogram_torch(preds, bin_centers_t, sigma)\n",
        "    loss = F.kl_div((hist+1e-12).log(), target_pdf_t, reduction='batchmean')\n",
        "    return loss\n",
        "\n",
        "# ---------------- Dataset ----------------\n",
        "class EmbDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return self.X[idx]\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# ---------------- Residual MLP Block ----------------\n",
        "class ResMLPBlock(nn.Module):\n",
        "    def __init__(self, d_model, mlp_expansion=MLP_EXPAND, drop=DROPOUT):\n",
        "        super().__init__()\n",
        "        hidden = d_model * mlp_expansion\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.fc1 = nn.Linear(d_model, hidden)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(hidden, d_model)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        # Pre-norm residual block\n",
        "        out = self.norm1(x)\n",
        "        out = self.fc1(out)\n",
        "        out = self.act(out)\n",
        "        out = self.drop(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.drop(out)\n",
        "        return x + out\n",
        "\n",
        "# ---------------- ResNet-MLP model ----------------\n",
        "class ResNetMLP(nn.Module):\n",
        "    def __init__(self, in_dim, d_model=HIDDEN_DIM, num_blocks=NUM_BLOCKS, mlp_expansion=MLP_EXPAND, drop=DROPOUT):\n",
        "        super().__init__()\n",
        "        # input projection\n",
        "        self.input_proj = nn.Sequential(\n",
        "            nn.Linear(in_dim, d_model),\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop)\n",
        "        )\n",
        "        # stack of residual blocks\n",
        "        self.blocks = nn.ModuleList([ResMLPBlock(d_model, mlp_expansion, drop) for _ in range(num_blocks)])\n",
        "        # final head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.Linear(d_model, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        for b in self.blocks:\n",
        "            x = b(x)\n",
        "        out = self.head(x).squeeze(-1)\n",
        "        return out\n",
        "\n",
        "# ---------------- Training loop with SWA + EMA ----------------\n",
        "kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n",
        "oof = np.zeros(len(X), dtype=np.float32)\n",
        "test_preds_folds = np.zeros((NFOLDS, X_test.shape[0]), dtype=np.float32)\n",
        "\n",
        "fold = 0\n",
        "for tr_idx, val_idx in kf.split(X):\n",
        "    print(f\"\\n========== Fold {fold} ==========\")\n",
        "    X_tr, X_val = X[tr_idx], X[val_idx]\n",
        "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
        "\n",
        "    train_dl = DataLoader(EmbDataset(X_tr, y_tr), batch_size=BATCH, shuffle=True, pin_memory=True)\n",
        "    val_dl   = DataLoader(EmbDataset(X_val, y_val), batch_size=BATCH, shuffle=False, pin_memory=True)\n",
        "    test_dl  = DataLoader(EmbDataset(X_test), batch_size=BATCH, shuffle=False, pin_memory=True)\n",
        "\n",
        "    model = ResNetMLP(INPUT_DIM, d_model=HIDDEN_DIM, num_blocks=NUM_BLOCKS, mlp_expansion=MLP_EXPAND, drop=DROPOUT).to(DEVICE)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
        "\n",
        "    swa_start = int(EPOCHS * SWA_START_FRAC)\n",
        "    swa_model = AveragedModel(model)\n",
        "    swa_count = 0\n",
        "\n",
        "    # EMA shadow params (store on CPU)\n",
        "    ema_shadow = {name: param.detach().cpu().clone() for name, param in model.named_parameters()}\n",
        "    ema_n = 0\n",
        "\n",
        "    mse_loss = nn.MSELoss()\n",
        "    best_rmse = 1e9\n",
        "    best_state = None\n",
        "    patience = 0\n",
        "\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        total_loss = total_mse = total_kl = ns = 0\n",
        "        t0 = time.time()\n",
        "        for xb, yb in train_dl:\n",
        "            xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
        "            opt.zero_grad()\n",
        "            preds = model(xb)\n",
        "            loss_mse = mse_loss(preds, yb)\n",
        "            loss_kl  = kl_hist_loss_torch(preds)\n",
        "            loss = loss_mse + LAMBDA_KL * loss_kl\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "\n",
        "            # EMA update (on CPU)\n",
        "            with torch.no_grad():\n",
        "                for name, param in model.named_parameters():\n",
        "                    ema_shadow[name] = EMA_DECAY * ema_shadow[name] + (1 - EMA_DECAY) * param.detach().cpu()\n",
        "\n",
        "            n_b = xb.size(0)\n",
        "            total_loss += float(loss.item()) * n_b\n",
        "            total_mse += float(loss_mse.item()) * n_b\n",
        "            total_kl  += float(loss_kl.item()) * n_b\n",
        "            ns += n_b\n",
        "\n",
        "        scheduler.step()\n",
        "        if ep > swa_start:\n",
        "            swa_model.update_parameters(model)\n",
        "            swa_count += 1\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        val_preds_list = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_dl:\n",
        "                xb = xb.to(DEVICE)\n",
        "                p = model(xb).detach().cpu().numpy()\n",
        "                val_preds_list.append(p)\n",
        "        val_preds = np.concatenate(val_preds_list, axis=0)\n",
        "        val_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
        "\n",
        "        avg_loss = total_loss / (ns + 1e-12)\n",
        "        print(f\"Ep {ep}/{EPOCHS} | loss={avg_loss:.5f} mse={total_mse/(ns+1e-12):.5f} kl={total_kl/(ns+1e-12):.5f} | val_RMSE={val_rmse:.4f} | time={time.time()-t0:.1f}s\")\n",
        "\n",
        "        if val_rmse < best_rmse:\n",
        "            best_rmse = val_rmse\n",
        "            best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "            patience = 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience >= 4 and ep > 8:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "    print(f\"Fold {fold} finished. best_val_rmse={best_rmse:.4f} swa_count={swa_count}\")\n",
        "\n",
        "    # choose final model: SWA if available\n",
        "    if swa_count > 0:\n",
        "        eval_model = ResNetMLP(INPUT_DIM, d_model=HIDDEN_DIM, num_blocks=NUM_BLOCKS, mlp_expansion=MLP_EXPAND, drop=DROPOUT).to(DEVICE)\n",
        "        swa_state = swa_model.module.state_dict() if hasattr(swa_model, \"module\") else swa_model.state_dict()\n",
        "        eval_model.load_state_dict(swa_state)\n",
        "    else:\n",
        "        eval_model = ResNetMLP(INPUT_DIM, d_model=HIDDEN_DIM, num_blocks=NUM_BLOCKS, mlp_expansion=MLP_EXPAND, drop=DROPOUT).to(DEVICE)\n",
        "        eval_model.load_state_dict(best_state)\n",
        "\n",
        "    # build EMA model and save both\n",
        "    ema_model = ResNetMLP(INPUT_DIM, d_model=HIDDEN_DIM, num_blocks=NUM_BLOCKS, mlp_expansion=MLP_EXPAND, drop=DROPOUT).to(DEVICE)\n",
        "    ema_state = ema_model.state_dict()\n",
        "    for n in ema_state.keys():\n",
        "        if n in ema_shadow:\n",
        "            ema_state[n] = ema_shadow[n].to(DEVICE)\n",
        "    ema_model.load_state_dict(ema_state)\n",
        "\n",
        "    torch.save(eval_model.state_dict(), f\"resnetmlp_fold{fold}.pt\")\n",
        "    torch.save(ema_model.state_dict(), f\"resnetmlp_ema_fold{fold}.pt\")\n",
        "    print(f\"Saved resnetmlp_fold{fold}.pt and resnetmlp_ema_fold{fold}.pt\")\n",
        "\n",
        "    # OOF preds (eval_model)\n",
        "    eval_model.eval()\n",
        "    val_preds_list = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_dl:\n",
        "            p = eval_model(xb.to(DEVICE)).cpu().numpy()\n",
        "            val_preds_list.append(p)\n",
        "    oof[val_idx] = np.concatenate(val_preds_list)\n",
        "\n",
        "    # test preds\n",
        "    test_fold_list = []\n",
        "    with torch.no_grad():\n",
        "        for xb in test_dl:\n",
        "            p = eval_model(xb.to(DEVICE)).cpu().numpy()\n",
        "            test_fold_list.append(p)\n",
        "    test_preds_folds[fold] = np.concatenate(test_fold_list)\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# ---------------- OOF eval + linear calibration ----------------\n",
        "oof_rmse_raw = np.sqrt(mean_squared_error(y, oof))\n",
        "print(\"\\nOOF RMSE (raw):\", oof_rmse_raw)\n",
        "\n",
        "lr_cal = LinearRegression().fit(oof.reshape(-1,1), y)\n",
        "oof_cal = lr_cal.predict(oof.reshape(-1,1))\n",
        "oof_rmse_cal = np.sqrt(mean_squared_error(y, oof_cal))\n",
        "print(\"OOF RMSE (calibrated):\", oof_rmse_cal)\n",
        "print(\"Calibration params: a=\", lr_cal.coef_[0], \"b=\", lr_cal.intercept_)\n",
        "\n",
        "# ---------------- PER-FOLD quantile mapping ----------------\n",
        "kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n",
        "fold_val_idxs = [val_idx for _, val_idx in kf.split(X)]\n",
        "sampled_vals = np.random.choice(BIN_CENTERS, size=200_000, p=TARGET_PDF)\n",
        "\n",
        "def quantile_match_array(preds_raw, sampled_vals):\n",
        "    order = np.argsort(preds_raw)\n",
        "    ranks = np.empty_like(order)\n",
        "    ranks[order] = np.arange(len(preds_raw))\n",
        "    q = ranks.astype(np.float32) / (len(preds_raw)-1 + 1e-12)\n",
        "    return np.quantile(sampled_vals, q)\n",
        "\n",
        "mapped_test_folds = np.zeros_like(test_preds_folds)\n",
        "for f in range(NFOLDS):\n",
        "    print(\"Quantile mapping fold\", f)\n",
        "    val_idx = fold_val_idxs[f]\n",
        "    val_preds_fold = oof[val_idx]\n",
        "    # safe check\n",
        "    val_preds_fold = np.nan_to_num(val_preds_fold, nan=np.nanmedian(val_preds_fold))\n",
        "    mapped_test_folds[f] = quantile_match_array(test_preds_folds[f], sampled_vals)\n",
        "\n",
        "test_mean_mapped = mapped_test_folds.mean(axis=0)\n",
        "test_calibrated = lr_cal.predict(test_mean_mapped.reshape(-1,1)).reshape(-1)\n",
        "test_final = np.clip(test_calibrated, 0.0, 10.0)\n",
        "\n",
        "# ---------------- Save submission ----------------\n",
        "if \"test_df\" not in globals():\n",
        "    import json\n",
        "    with open(\"test_data.json\",\"r\",encoding=\"utf8\") as f:\n",
        "        test_raw = json.load(f)\n",
        "    test_df = pd.DataFrame(test_raw)\n",
        "\n",
        "test_df[\"ID\"] = np.arange(1, len(test_final)+1)\n",
        "sub = pd.DataFrame({\"ID\": test_df[\"ID\"], \"score\": test_final})\n",
        "sub.to_csv(\"submission_resnetmlp_histKL_swa_ema_perfold.csv\", index=False)\n",
        "print(\"\\nSaved submission_resnetmlp_histKL_swa_ema_perfold.csv\")\n",
        "\n",
        "print(\"\\nFINAL OOF RMSE (raw):\", oof_rmse_raw, \"OOF RMSE (cal):\", oof_rmse_cal)\n"
      ],
      "metadata": {
        "id": "Mc4SpS6TPOJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# ===========================\n",
        "# Load submission file\n",
        "# ===========================\n",
        "sub = pd.read_csv(\"submission_final02.csv\")\n",
        "\n",
        "scores = sub[\"score\"].values\n",
        "print(\"Loaded predictions:\", scores.shape)\n",
        "\n",
        "# Create folder\n",
        "FIG_DIR = \"figures_submission\"\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "print(\"Saving figures to:\", FIG_DIR)\n",
        "\n",
        "# ===========================\n",
        "# 1. Histogram\n",
        "# ===========================\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(scores, bins=40, kde=True, color=\"purple\")\n",
        "plt.title(\"Final Prediction Score Distribution\")\n",
        "plt.xlabel(\"Predicted Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/histogram_scores.png\")\n",
        "plt.close()\n",
        "\n",
        "# ===========================\n",
        "# 2. Boxplot\n",
        "# ===========================\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x=scores, color=\"orange\")\n",
        "plt.title(\"Prediction Score Boxplot\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/boxplot_scores.png\")\n",
        "plt.close()\n",
        "\n",
        "# ===========================\n",
        "# 3. Violin plot\n",
        "# ===========================\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.violinplot(x=scores, color=\"green\")\n",
        "plt.title(\"Prediction Score Violin Plot\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/violin_scores.png\")\n",
        "plt.close()\n",
        "\n",
        "# ===========================\n",
        "# 4. Sorted predictions scatter\n",
        "# ===========================\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(np.arange(len(scores)), np.sort(scores), s=8, alpha=0.7)\n",
        "plt.title(\"Sorted Predictions Curve\")\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"Predicted Score\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/sorted_scores.png\")\n",
        "plt.close()\n",
        "\n",
        "# ===========================\n",
        "# 5. CDF (cumulative distribution)\n",
        "# ===========================\n",
        "sorted_scores = np.sort(scores)\n",
        "cdf = np.arange(len(scores)) / (len(scores) - 1)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(sorted_scores, cdf, linewidth=2)\n",
        "plt.title(\"Cumulative Distribution Function of Predictions\")\n",
        "plt.xlabel(\"Score\")\n",
        "plt.ylabel(\"CDF\")\n",
        "plt.grid(alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/cdf_scores.png\")\n",
        "plt.close()\n",
        "\n",
        "# ===========================\n",
        "# 6. 2D heatmap (score frequency in ranges)\n",
        "# ===========================\n",
        "bins = np.linspace(0, 10, 21)\n",
        "hist, edges = np.histogram(scores, bins=bins)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "sns.heatmap(hist.reshape(1,-1), annot=True, fmt=\"d\", cmap=\"magma\")\n",
        "plt.yticks([], [])\n",
        "plt.xticks(np.arange(len(edges)-1)+0.5, [f\"{edges[i]:.1f}-{edges[i+1]:.1f}\" for i in range(len(edges)-1)], rotation=90)\n",
        "plt.title(\"Heatmap of Score Frequencies\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/heatmap_score_bins.png\")\n",
        "plt.close()\n",
        "\n",
        "# ===========================\n",
        "# 7. Outlier detection (z-score)\n",
        "# ===========================\n",
        "z = (scores - scores.mean()) / scores.std()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(np.arange(len(z)), z, s=10)\n",
        "plt.axhline(+3, color='red', linestyle='--')\n",
        "plt.axhline(-3, color='red', linestyle='--')\n",
        "plt.title(\"Outlier Detection via Z-score\")\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"Z-score\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/outlier_detection.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"All visualizations saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOjp0L3PRMlI",
        "outputId": "46ee582b-ee76-4cab-9c7b-089586c372c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded predictions: (3638,)\n",
            "Saving figures to: figures_submission\n",
            "All visualizations saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HP7BlFe5SDR8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}